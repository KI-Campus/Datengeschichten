{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f53966",
   "metadata": {},
   "source": [
    "# Quantitative Textanalyse: *Word Clouds*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae67d67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Schön, dass du wieder dabei bist! In diesem *Notebook* wollen wir uns damit beschäftigen, wie man sogenannte *Word Clouds* oder *Wortwolken* in R erzeugen kann. \n",
    "\n",
    "Hierzu nutzen wir zunächst den Text der Wikipediaseite der Stadt Bielefeld (https://de.wikipedia.org/wiki/Bielefeld)! Mit dieser *Word Cloud* können wir visualisieren, welche Worte auf der Wikipediaseite besonders häufig genannt werden. Oder anders ausgedrückt, wir können untersuchen, wie die **Stadt Bielefeld** auf Wikipedia dargestellt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d927188",
   "metadata": {},
   "source": [
    "## Was sind Word Clouds und für welche Informationen kann man sie gut nutzen?\n",
    "\n",
    "<img width=\"440\" align = \"right\" hspace=\"40\" src=\"WordcloudDataStorytelling.png\"/> \n",
    "\n",
    "<div style=\"text-align: left\" style=“line-height: 150%“>\n",
    "<p></p>  \n",
    "<p><b>Wortwolken</b> oder <b>Word Clouds</b> ermöglichen die visuelle Darstellung von Textinhalten. Die hier dargestellte Wortwolke visualisiert unterschiedliche Definitionen des Begriffs <i>Data Storytelling</i>. In unserem Beispiel schauen wir uns hierzu später den <b>Wikipediaartikel der Stadt Bielefeld</b> an.</p> \n",
    "\n",
    "<p>Es lassen sich auch ganz andere Textformen oder auch Textelemente mit Hilfe von Word Clouds visualisieren, egal ob Wikipediaartikel, PDF-Dokumente, Twitter-Feeds oder ganze Bücher, fast jede Textform ist nutzbar.</p> \n",
    "    \n",
    "Die Wörter aus denen eine Word Cloud besteht sind zum Beispiel **unterschiedlich groß**. Je größer ein Wort in der Wortwolke ist, desto häufiger wird es im zugrundeliegenden Text genutzt. Das größte Wort stellt beispielswiese den **Themenschwerpunkt** eines Textes heraus. Zusammen mit weiteren, etwas kleinern Wörtern der Word Cloud lassen sich so vielleicht schon **thematische Zusammenhänge** erkennen oder **besonders relevante Themen** eines Textes.\n",
    "</div>      \n",
    "\n",
    "Neben der **Größe** gibt es noch andere Möglichkeiten, die Häufigkeit bestimmter Wörter innerhalb eines Textes mithilfe von Word Clouds zu visualisieren. Beispielsweise über eine **farbliche Kennzeichnung**. Das sieht dann zum Beispiel so aus, dass das meistgenutzte Wort in rot hervorgehoben wird (natürlich sind auch andere Farben möglich oder die Farbzuordnung wird dem Zufall überlassen).\n",
    "\n",
    "Hierin liegt die **Stärke von Wortwolken**: Ohne, dass der ganze Text gelesen werden muss, kann mit dieser Visualisierungsform zügig ein erster Eindruck über das relevante Thema oder die relevanten Themen eines Textelements gewonnen werden.\n",
    "\n",
    "Gerade wenn Word Clouds in Präsentationen genutzt werden, bieten diese den Vorteil, mehr Aufmerksamkeit auf sich zu ziehen als eine schlichte Auflistung von thematischen Schwerpunkten eines Textes.\n",
    "\n",
    "In R lassen sich die Möglichkeiten zur Visualisierung einer Wortwolke ganz einfach umsetzten. Egal, ob über die Größe der Wörter oder eine farbliche Unterscheidung – auch eine Kombination verschiedener Visualisierungsformen ist möglich. R bietet uns die Möglichkeit, selbst eine Word Cloud zu erstellen.\n",
    "\n",
    "Die erste Frage, die sich jetzt stellt, ist: ***Wie kann ich einen Text in R einlesen?***\n",
    "\n",
    "Hierfür gibt es verschiedene Lösungen. Abhängig davon, in welcher Form der Text vorliegt, können wir die Aufgabe über entsprechende Pakete und Befehle lösen.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89af01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**Gut zu wissen**: Wir werden dir in diesem Notebook auch einige Vorgehensweisen zeigen, die dann besonders wichtig werden, wenn du mit einer eigenen RStudio-Installation und nicht mit einem Jupyter Notebook arbeitest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca18325",
   "metadata": {},
   "source": [
    "# Word Cloud in R erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3b1ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## R-Projekt für die Word Cloud anlegen\n",
    "Als erstes erstellen wir in RStudio ein neues *Projekt*. Dazu klickt man auf \"File\", dann auf \"New Project...\" und anschließend auf \"New Directory\". Als \"Project Type\" wählt man \"New Project\". Nun geben wir unserem Projekt einen Namen und wählen den Speicherort auf unserem Rechner aus. Den Speicherort oder den Speicherpfad merken wir uns, diesen brauchen wir gleich. R erstellt nun ein neues Projekt.\n",
    "\n",
    "Die Texte, die wir als Dateien vorliegen haben und für die Word Cloud nutzen wollen kopieren wir nun in diesen Ordner. Den Wikipedia Eintrag der Stadt Bielefeld haben wir als Textdatei vorliegen, das Dateiformat lässt sich an der Dateiendung `.txt` erkennen. (Falls die Dateiendung bei dir nicht angezeigt wird, kannst du auch mit einem Rechtsklick auf die Datei unter Eigenschaften den Dateityp nachsehen). Jetzt befindet sich die Datei im Projektordner und wir können beginnen das Script zum Generieren einer Word Cloud zu erstellen.du kannst auch ein bestehendes Projekt nutzen, dann muss die Textdatei einfach in den entsprechenden Ordner eingefügt werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a7d23",
   "metadata": {},
   "source": [
    "## Script für die Word Cloud: Pakete installieren und laden\n",
    "Im ersten Schritt installieren wir alle Pakete, die Befehle und Funktionen enthalten, die wir benötigen. Da die **PAkete** in unserer Jupyter Notebook Umgebung bereits vorinstalliert sind, sind die Pakete hier auskommentiert. In R selbst müsstest du sie aber bei der Erstbenutzung zunächst installieren.\n",
    "\n",
    "Außerdem müssen wir diese Pakte sozusagen in R noch aktivieren. Das erfolgt mit dem `library()` Befehl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installieren der Pakete, die zum  Erstellen einer Word Cloud benötigt werden\n",
    "\n",
    "#install.packages(\"tm\")\n",
    "#install.packages(\"SnowballC\")\n",
    "#install.packages(\"Word Cloud\")\n",
    "#install.packages(\"wordcloud2\")\n",
    "#install.packages(\"RColorBrewer\")\n",
    "#install.packages(\"stringi\")\n",
    "#install.packages(\"Rcpp\")\n",
    "\n",
    "\n",
    "# Laden der benötigten Pakete\n",
    "\n",
    "library(\"tm\")\n",
    "library(\"SnowballC\")\n",
    "library(\"Word Cloud\")\n",
    "library(\"RColorBrewer\")\n",
    "library(\"stringi\")\n",
    "library(\"Rcpp\")\n",
    "library(\"NLP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df922617",
   "metadata": {},
   "source": [
    "## Script für die Word Cloud: Text einlesen\n",
    "Wir erstellen zunächst ein Objekt `Wiki-Bielefeld`. Diesem Objekt weisen wir unseren Text als Inhalt zu. Hierzu lesen wir den Text in R ein. R liest mit Hilfe des Befehls `stri_read_lines()` den Text als Ganzes ein und teilt den Text dabei in einzelne Textzeilen auf. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3923a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des Textes Zeile für Zeile\n",
    "\n",
    "Wiki_Bielefeld <- stri_read_lines(\"Bielefeld_Wikipedia_Eintrag.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5807a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Ausprobieren\n",
    "\n",
    "Las dir doch einmal das erstellte Objekt `Wiki_Bielefeld` ausgeben. Dann kannst du die Struktur sehen, mit der R den Text aufteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wiki_Bielefeld"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812350bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Script für die Word Cloud: Textkorpus erstellen\n",
    "In diesem Schritt fassen wir alle Texte, die wir in R mit den ersten drei Schritten eingelesen haben, zu einem **Textkorpus** zusammen. Bei unserem Beispiel handelt sich dabei nur um die Textdatei mit dem Wikipediaeintrag der Stadt Bielefeld. Wenn wir zum Beispiel eine Word Cloud zu allen Städten mit mehr als 100.000 Einwohner:innen in OWL erstellen wollen, würden wir auch die Wikipediaartikel der Städte Gütersloh und Paderborn zum Textkorpus hinzufügen, nachdem wir sie für R lesbar gemacht haben. Den so zusammengefassten Korpus weisen wir dem Objekt `docs` zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten als Corpus laden, auch für mehrere Dateien ist das notwendig\n",
    "\n",
    "docs <- Corpus(VectorSource(Wiki_Bielefeld))\n",
    "\n",
    "\n",
    "# Hier kannst du dir den erstellten Daten-Corpus noch einmal mit ansehen \n",
    "# Gerade bei mehreren Dateien, die zu einem Daten-Corpus zusammengefasst werden, ist das ratsam\n",
    "\n",
    "inspect(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a954142",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Script für die Word Cloud: Matrix anlegen und sortierten Datensatz erstellen\n",
    "\n",
    "Mit Hilfe des Objektes `docs` können wir nun eine **Matrix** mit den Wörtern aus unseren Texten anlegen. So wird die Frequenz oder die Häufigkeit, mit der die Wörter in unserem Texten vorkommen, zählbar gemacht. Außerdem werden die Wörter nach der Häufigkeit ihres Vorkommens sortiert. Beginnend beim Wort mit der höchsten Frequenz wird eine **absteigende Liste** erstellt. Diese sortierte Liste wird anschließend in einen eigenen Datensatz `d` geschrieben. Auf diesem basiert dann im nächsten Schritt unsere Word Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier wird eine Matrix angelegt, die die Häufigkeit der Begriffe aus den Texten zählbar macht\n",
    "# Anlegen der Dokumenten-Matrix und Objektzuweisung\n",
    "\n",
    "dtm <- TermDocumentMatrix(docs)\n",
    "m <- as.matrix(dtm)\n",
    "\n",
    "\n",
    "# Absteigende Sortierung erstellen beginnend mit dem Wort, dass am meisten vorkommt\n",
    "v <- sort(rowSums(m),decreasing=TRUE)\n",
    "\n",
    "# Datensatz erstellen, der die Wörter mit ihrer Freqenz enthält und nach der vorher angelegten Sortierung sortiert ist\n",
    "d <- data.frame(word = names(v),freq=v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64db0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Script für die Word Cloud:  Word Cloud erstellen\n",
    "Jetzt können wir mit dem Dataframe `d` als Basis eine Word Cloud erstellen. Als erstes legen wir den **Seed** fest. Das heißt, die Word Cloud wird immer nach dem gleichen Schema erstellt. Der Vorteil hierbei ist, dass so die Word Cloud reproduzierbar ist und nicht jedes Mal mit einem neuen Aussehen erstellt wird.\n",
    "\n",
    "Dann legen wir fest, dass unsere Word Cloud aus den Wörtern, die in unserem Dataframe enthalten sind besteht `(d$words)` und dabei nach der Freqenz der Worthäufigkeiten strukturiert ist `(d$freq)`. Über `min.freq` legen wir fest, wie oft  ein Wort mindestens in unserem Datensatz `d` vorkommen muss, damit es in die WortCloud übernommen wird. Wir können auch begrenzen, aus wie vielen Wörtern die Word Cloud besteht. \n",
    "\n",
    "Die Anordnung der Wörter kann zufällig erfolgen. Wir lassen unsere Wortwolke aber nicht zufällig erstellen. Dies erfolgt über `random.order=FALSE`. Mit dem Wert 0.35 (35%) legen wir fest, welcher Anteil an Wörtern  nicht waagerecht dargestellt wird. Der letzte Ausdruck legt die Farbauswahl für die Word Cloud fest.\n",
    "\n",
    "***Was fällt dir beim Erstellen der Word Cloud auf?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6aae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Festlegen einer Vorlage für die Word Cloud, damit diese reproduziert werden kann und nicht\n",
    "# bei jeder Erstellung zufällig erstellt wird\n",
    "\n",
    "set.seed(1234)\n",
    "\n",
    "# Erstellen der Word Cloud - die Wörter mit der höchsten Frequenz (freq) werden am größten dargestellt\n",
    "# die minimale Frequenz damit ein Wort dargestellt wird ist 1\n",
    "# die Word Cloud besteht aus max. 100 Wörtern (max.Words)\n",
    "# die Anordnung ist nicht zufällig\n",
    "# rot.per --> legt fest welcher Anteil an Wörtern nicht waagerecht dargestellt wird\n",
    "\n",
    "Wortwolke1 <- Word Cloud(words = d$word, freq = d$freq,scale=c(12,1), min.freq = 1,\n",
    "          max.words=100, random.order=FALSE, rot.per=0.35, \n",
    "          colors=brewer.pal(8, \"Dark2\"))\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94baf85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Stop Words - \"Stopp-Wörter\" und weitere Aufbereitung\n",
    "\n",
    "**Die erstellte Word Cloud ist noch nicht aussagekräftig!** \n",
    "\n",
    "Die Wörter, die am häufigsten vorkommen sind „der“, „die“, „das“, „und“ und ähnliche. Diese Wörter kommen gerade in deutschen Texten sehr oft vor, sind für die Word Cloud aber nicht besonders aussagekräftig. Um die Texte, die wir benutzen, von diesen *Füllwörtern* zu befreien gibt, es für R **Stop-Word-Listen**. Diese entfernen alle gängigen Wörter, wie eben „der“, „die“, „das“ und „und“ aus der Liste der Wörter, die in die Word Cloud übernommen werden. \n",
    "\n",
    "Hierzu weisen wir unserem erstellten Korpus-Objekt `docs` mit einem Befehl einfach diese Stop-Word-Liste zu und die Wörter der Liste fallen aus der Wertung. Diese Stop-Word-Listen gibt es dabei für verschiedene Sprachen.\n",
    "\n",
    "Außer den Stopp-Wörtern, ist es außerdem sinnvoll Zahlen (z.B. ausgeschriebene Jahreszahlen wie \"1995\"), überflüssige Leerzeichen oder auch die Zeichensetzung zu entfernen, um möglichst nur auf die relevanten Informationen und die relevanten Wörter zuzugreifen. \n",
    "\n",
    "Analysiert man beispielsweise ein Twitter-Feed, ist es außerdem sinnvoll weitere Sonderzeichen wie die Raute (#) zu entfernen oder auch das @-Zeichen. Zusätzlich kann man alle Buchstaben als Kleinbuchstaben definieren, um ein einheitliches Schriftbild zu erhalten.\n",
    "\n",
    "Diese Bereinigungen weisen wir hierzu nach und nach unserem Korpus-Objekt zu. \n",
    "\n",
    "***Schau dir die Word Cloud an, die nach der Aufbereitung entsteht. Was fällt dir auf?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Stop Words - \"Stopp-Wörter\" und weitere Aufbereitung###\n",
    "\n",
    "# Alle Großbuchstaben werden zu Kleinbuchstaben \n",
    "docs <- tm_map(docs, content_transformer(tolower))\n",
    "\n",
    "\n",
    "# Stoppwörter entfernen z.B. der, die, das, und usw. Deutsch und Englisch\n",
    "docs <- tm_map(docs, removeWords, stopwords(\"english\"))\n",
    "docs <- tm_map(docs, removeWords, stopwords(\"german\"))\n",
    "\n",
    "\n",
    "# Zahlen entfernen\n",
    "docs <- tm_map(docs, removeNumbers)\n",
    "\n",
    "# Überschüssige Leerzeichen entfernen\n",
    "docs <- tm_map(docs, stripWhitespace)\n",
    "\n",
    "# Zeichensetzung entfernen\n",
    "docs <- tm_map(docs, removePunctuation)\n",
    "\n",
    "# Text aufbereiten, entfernen von Sonderzeichen\n",
    "toSpace <- content_transformer(function (x , pattern ) gsub(pattern, \" \", x))\n",
    "docs <- tm_map(docs, toSpace, \"/\")\n",
    "docs <- tm_map(docs, toSpace, \"@\")\n",
    "docs <- tm_map(docs, toSpace, \"\\\\|\")\n",
    "\n",
    "\n",
    "# Hier wird eine Matrix angelegt, die die Häufigkeit der Begriffe aus den Texten zählbar macht\n",
    "dtm <- TermDocumentMatrix(docs)\n",
    "m <- as.matrix(dtm)\n",
    "v <- sort(rowSums(m),decreasing=TRUE)\n",
    "d <- data.frame(word = names(v),freq=v)\n",
    "\n",
    "\n",
    "# Festlegen einer \"Vorlage\" für die Word Cloud, damit diese reproduziert werden kann und nicht\n",
    "# bei jeder Erstellung zufällig erstellt wird\n",
    "set.seed(1234)\n",
    "\n",
    "\n",
    "# Erstellen der Word Cloud - die Wörter mit der höchsten Frequenz (freq) werden am größten dargestellt\n",
    "# Die minimale Frequenz damit ein Wort dargestellt wird ist 1\n",
    "# Die Word Cloud besteht aus max. 100 Wörtern (max.Words)\n",
    "# dDe Anordnung ist nicht zufällig\n",
    "# rot.per legt fest welcher Anteil an Wörtern nicht waagerecht dargestellt wird\n",
    "wordcloud2 <- Word Cloud(words = d$word, freq = d$freq, scale=c(8,1), min.freq = 1,\n",
    "          max.words=100, random.order=FALSE, rot.per=0.35, \n",
    "          colors=brewer.pal(8, \"Dark2\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc49ce9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Eigene Stopwords\n",
    "\n",
    "Wie du in der zuletzt erstellten Word Cloud siehst, reicht je nach Text die Aufbereitung mit den vordefinierten Stoppwörter-Listen noch nicht aus und wir finden immer noch Wörter, die unsere Word Cloud in ihrer Aussagefähigkeit einschränken. Um auch diese Wörter aus der Word Cloud auszuschließen zu können, können wir eigene Wörter als Stop Words definieren. Diese Liste weisen wir wiederum unserem Objekt `docs` zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c155cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Eigene Stop-Words###\n",
    "docs <- tm_map(docs, removeWords, c(\"sowie\", \"wurden\", \"seit\", \"heute\", \"heut\", \n",
    "                \"teil\", \"befindet\", \"weiter\", \"erst\", \"etwa\", \"rund\", \"gibt\", \n",
    "                \"liegt\", \"zwei\", \"statt\", \"weitere\", \"finden\", \"erste\")) \n",
    "\n",
    "\n",
    "\n",
    "# Hier wird eine Matrix angelegt die die Häufigkeit der Begriffe aus den Texten zählbar macht\n",
    "dtm <- TermDocumentMatrix(docs)\n",
    "m <- as.matrix(dtm)\n",
    "v <- sort(rowSums(m),decreasing=TRUE)\n",
    "d2 <- data.frame(word = names(v),freq=v)\n",
    "\n",
    "\n",
    "# Festlegen einer \"Vorlage\" für die Word Cloud, damit diese reproduziert werden kann und nicht\n",
    "# bei jeder Erstellung zufällig erstellt wird\n",
    "set.seed(1234)\n",
    "\n",
    "\n",
    "# Erstellen der Word Cloud - die Wörter mit der höchsten Frequenz (freq) werden am größten dargestellt\n",
    "# Die minimale Frequenz damit ein Wort dargestellt wird ist 1\n",
    "# Die Word Cloud besteht aus max. 100 Wörtern (max.Words)\n",
    "# Die Anordnung ist nicht zufällig\n",
    "# rot.per legt fest welcher Anteil an Wörtern nicht waagerecht dargestellt wird\n",
    "wordcloud3 <-Word Cloud(words = d$word, freq = d$freq,scale=c(8,1), min.freq = 1,\n",
    "          max.words=100, random.order=FALSE, rot.per=0.35, \n",
    "          colors=brewer.pal(8, \"Dark2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8322a8fa",
   "metadata": {},
   "source": [
    "## Ausprobieren\n",
    "In der Liste mit den eigenen Stop Words fehlen noch ein paar Wörter. Füge die Wörter zur Liste hinzu und lass dir die neue Word Cloud ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2378ba7",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccea241",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "###Eigene Stop-Words###\n",
    "docs <- tm_map(docs, removeWords, c(\"sowie\", \"wurden\", \"seit\", \"heute\", \"heut\",\n",
    "                \"teil\",\"befindet\", \"weiter\", \"erst\", \"etwa\", \"rund\", \"gibt\", \"liegt\",\n",
    "                \"zwei\",\"statt\",  \"weitere\", \"finden\", \"erste\",\"siehe\", \"wurde\",\n",
    "                \"viele\",\"jedoch\",\"mehrere\",\"isbn\")) \n",
    "\n",
    "\n",
    "\n",
    "# Hier wird eine Matrix angelegt die die Häufigkeit der Begriffe aus den Texten zählbar macht\n",
    "dtm <- TermDocumentMatrix(docs)\n",
    "m <- as.matrix(dtm)\n",
    "v <- sort(rowSums(m),decreasing=TRUE)\n",
    "d <- data.frame(word = names(v),freq=v)\n",
    "\n",
    "\n",
    "# Festlegen einer \"Vorlage\" für die Word Cloud, damit diese reproduziert werden kann und nicht\n",
    "# bei jeder Erstellung zufällig erstellt wird\n",
    "set.seed(1234)\n",
    "\n",
    "\n",
    "# Erstellen der Word Cloud - die Wörter mit der höchsten Frequenz (freq) werden am größten dargestellt\n",
    "# Die minimale Frequenz damit ein Wort dargestellt wird ist 1\n",
    "# Die Word Cloud besteht aus max. 100 Wörtern (max.Words)\n",
    "# Die Anordnung ist nicht zufällig\n",
    "# rot.per legt fest welcher Anteil an Wörtern nicht waagerecht dargestellt wird\n",
    "wordcloud3 <-Word Cloud(words = d$word, freq = d$freq, scale=c(8,1), min.freq = 1,\n",
    "          max.words=100, random.order=FALSE, rot.per=0.35, \n",
    "          colors=brewer.pal(8, \"Dark2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fb75e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Hinweis\n",
    "Es gibt darüber hinaus die Möglichkeit, mit einem weiteren Befehl Wörter auf ihren Wortstamm zu reduzieren. Beispielsweise werden so die Wörter „Bielefeld“ und „Bielefelder“ zusammengefasst. Das kann je nach Forschungsinteresse oder Fragestellung durchaus nützlich sein. Wir verzichten hier jedoch auf diesen Befehl, dieser führt stellenweise nämlich auch zur Verfälschung des Analyseergebnisses und kürzt unter anderem Wortendungen weg. Den entsprechenden Befehl und die Word Cloud, die mit ihm ausgegeben wird, siehst du, wenn du das folgende Skript ausführst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Hinweis###\n",
    "\n",
    "# Wörter auf ihren Wortstamm reduzieren, sodass beispielsweise Bielfelder und Bielefeld zusammengefasst werden\n",
    "docs <- tm_map(docs, stemDocument)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hier wird eine Matrix angelegt die die Häufigkeit der Begriffe aus den Texten zählbar macht\n",
    "dtm <- TermDocumentMatrix(docs)\n",
    "m <- as.matrix(dtm)\n",
    "v <- sort(rowSums(m),decreasing=TRUE)\n",
    "d <- data.frame(word = names(v),freq=v)\n",
    "\n",
    "\n",
    "# Festlegen einer \"Vorlage\" für die Word Cloud, damit diese reproduziert werden kann und nicht\n",
    "# bei jeder Erstellung zufällig erstellt wird\n",
    "set.seed(1234)\n",
    "\n",
    "\n",
    "# Erstellen der Word Cloud - die Wörter mit der höchsten Frequenz (freq) werden am größten dargestellt\n",
    "# Die minimale Frequenz damit ein Wort dargestellt wird ist 1\n",
    "# Die Word Cloud besteht aus max. 100 Wörtern (max.Words)\n",
    "# Die Anordnung ist nicht zufällig\n",
    "# rot.per legt fest welcher Anteil an Wörtern nicht waagerecht dargestellt wird\n",
    "Word Cloud(words = d$word, freq = d$freq, scale=c(8,1), min.freq = 1,\n",
    "          max.words=100, random.order=FALSE, rot.per=0.35, \n",
    "          colors=brewer.pal(8, \"Dark2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b48d59d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Websites direkt auslesen und eine Word Cloud erstellen\n",
    "Mit R lassen sich nicht nur Textdateien auswerten, du kannst auch direkt auf **Websites** zugreifen und die Texte dort für die Erstellung von Word Clouds nutzen. An den Befehlen für die Aufbereitung der Texte ändert sich nichts. Es gibt ein paar Ergänzungen, aber den generellen Ablauf kennen wir schon aus der Erstellung der Word Cloud auf Basis von Textdokumenten.\n",
    "\n",
    "Wir benötigen allerdings zusätzliche R-Funktionen und Befehle. Hierzu installieren und laden wir einige neue Pakete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benötigte Pakete\n",
    "library(\"rvest\")\n",
    "library(\"dplyr\")\n",
    "library(\"htmltools\")\n",
    "library(\"tm\")\n",
    "library(\"SnowballC\")\n",
    "library(\"Word Cloud\")\n",
    "library(\"wordcloud2\")\n",
    "library(\"RColorBrewer\")\n",
    "library(\"stringi\")\n",
    "library(\"magrittr\") \n",
    "library(\"dplyr\")    \n",
    "library(\"ggplot2\")\n",
    "library(\"xml2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cef82e",
   "metadata": {},
   "source": [
    "## Websites mit R lesen\n",
    "Um Websites mit R zu lesen, benötigen wir zunächst die URL der Seite, die wir nutzen möchten. Wir bleiben bei unserem Beispiel, dem Wikipediaeintrag der Stadt Bielefeld.\n",
    "\n",
    "Dieser ist unter der Adresse https://de.wikipedia.org/wiki/Bielefeld zu erreichen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7a51b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## URL Adresse \n",
    "Die URL-Adresse definieren wir als eigenes Objekt, somit müssen wir nicht immer den kompletten Link angeben müssen. Das neuerstellte Objekt ist `Wiki_Bi_Eintrag`.\n",
    "\n",
    "## HTML und XML einlesen\n",
    "Textdokumente, wie .txt-Dateien und Websites, unterscheiden sich in Bezug auf ihre Formatierung, da es sich um völlig unterschiedliche Quellen für das gleiche Textelement handelt. Um die Website mit R einzulesen, nutzen wir daher den Befehl `read_html()`. Dies macht das Format der Website für R nutzbar. Den Inhalt, den wir damit auslesen, weisen wir dem neuen Objekt `Wiki_Bi_html` zu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a00527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrufen des Wikipedia Artikels der Stadt Bielefeld über die URL \n",
    "Wiki_Bi_Eintrag <- \"https://de.wikipedia.org/wiki/Bielefeld\"\n",
    "\n",
    "Wiki_Bi_html <- read_html(Wiki_Bi_Eintrag)\n",
    "\n",
    "Wiki_Bi_html\n",
    "str(Wiki_Bi_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9bbb3",
   "metadata": {},
   "source": [
    "### Kurzer Exkurs: Quellcode\n",
    "\n",
    "Um von einer Website nur den relevanten Text für die **Word Cloud** zu nutzen, ist ein Blick in den Quellcode der Website notwendig. Keine Sorge, das klingt komplizierter als es eigentlich ist. \n",
    "\n",
    "Öffne in einem Browser Deiner Wahl (*Firefox, Google Chrome, Opera, Microsoft Edge*) den Wikipediaeintrag der Stadt Bielefeld. Klicke jetzt mit der rechten Maustaste irgendwo auf die Seite, zum Beispiel neben das Wappen von Bielefeld. In dem Kontextmenü, das sich öffnet, klickst du auf „Untersuchen“. In deinem Browser öffnet sich jetzt ein neues Menü neben dem Wikipediaeintrag. Dieses Fenster zeigt an, aus welchen Elementen die Seite besteht. \n",
    "\n",
    "Ganz oben in dem neuen Menü ist ein Button, auf dem ein kleiner Mauszeiger zu sehen ist. Wenn du auf diesen Button klickst, leuchtet dieser blau auf und ist aktiviert. Sobald du irgendwo anders draufklickst, deaktiviert sich dieser Button wieder. Lass den Button aktiviert und fahr einfach über den Wikipedia-Eintrag ohne etwas anzuklicken. \n",
    "\n",
    "Es leuchten  verschiedene Kästchen blau auf. Teilweise sind die auch noch mit einem orangefarbenen Rahmen versehen. Wenn du zum Beispiel den Mauszeiger auf das Wikipedia-Logo bewegst, ist dieses blau hinterlegt. Außerdem siehst du unter dem Logo eine kleine Textbox. Der Titel dieser Box lautet: „a.mw-wiki-logo“. Das sind HTML-Element und CSS-Klasse des Logos auf der Website. Mit der CSS-Klasse lassen sich später alle Elemente der Website finden, die auch zu dieser Klasse gehören. Dabei sind HTML-Element und CSS-Klasse mit einem Punkt voneineander getrennt. In diesem Beispiel ist das Logo in einem „a“ HTML-Element (das macht das Bild zu einem anklickbaren Link) und hat die CSS-Klasse „mw-wiki-logo“ (damit wird die Dastellung des Bildes gesteuert).\n",
    "\n",
    "Für die Word Cloud brauchen wir das Wikipedia-Logo oder auch die linke Navigationsleiste für den Wikipedia Artikel nicht. Wir schauen daher zu welcher CSS-Klasse der Textkörper des Wikipediaartikels gehört.\n",
    "\n",
    "Wenn du den Mauszeiger auf die freie Fläche zwischen „Inhaltsverzeichnis“ und der Tabelle mit den „Basisdaten“ auf der rechten Seite bewegst, leuchtet der ganze Text blau auf oder ist blau hinterlegt.\n",
    "Das ist das für uns relvante Element auf der Website des Wikipediaeintrags der Stadt Bielefeld: \"div.mw-parser-output\". Auch hier sind wieder HTML-Element und CSS-Klasse involviert: „div“ (das fügt alle anderen Elemente, die in diesem div-Element enhalten sind, zusammen) und „mw-parser-output“ (auch hiermit wird die Darstelliung gesteuert). Da wir nicht alle div-Elemente haben möchten, sondern nur die, die zur Klasse „mw-parser-output“ gehören, können wir das „div“ streichen. Für das Einlesen in R reicht uns die Klasse: „.mw-parser-output“."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f7254",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Einlesen des relevanten Textelements von einer Website\n",
    "Nachdem wir ermittelt haben, wie genau der Text, der uns interessiert, auf der Webseite zu finden ist, können wir ihn in R einlesen. Hierzu schreiben wir den Text in ein neues Objekt, sodass dieses Objekt nur noch den Text beinhaltet. Dies gelingt uns mit dem folgenden Skript. Anschließend geben wir das Objekt zur Überprüfung aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff62720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Einlesen des Inhaltes / Textes --> über den Pfad .mw-parser-output \n",
    "#hierzu ist ein Auslesen des Quellcodes der Internetseite notwendig\n",
    "\n",
    "Wiki_Bi_Text <-(Wiki_Bi_html %>%\n",
    "                  html_node(\".mw-parser-output\") %>%\n",
    "                  html_text())\n",
    "\n",
    "\n",
    "#Ausgabe des Textes zur Überprüfung\n",
    "Wiki_Bi_Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ca74c4",
   "metadata": {},
   "source": [
    "## Text Ausgabe\n",
    "Dir ist bestimmt aufgefallen, dass der Text, den du gerade ausgegeben hast, noch etwas chaotisch aussieht. Das liegt unter anderem daran, das zum Beispiel auch die Zeilenumbrüche \"\\n\" im Textelemt als Text vermerkt sind.\n",
    "\n",
    "Du kannst dir mit dem nachfolgenden Befehl den Text ausgeschrieben ausgeben lassen, das sieht dann schon deutlich übersichtlicher aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ddb2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ausgabe des Textes in Zeilen, das ist wesentlich übersichtlicher\n",
    "writeLines(Wiki_Bi_Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efe66c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Ausgabe in Textdatei\n",
    "Bevor wir eine Word Cloud aus dem Textobjekt `Wiki_Bi_Text` erstellen, speichern wir den Text mit Hilfe von R in einer seperaten Textdatei ab. Diese Datei wird innerhalb des Befehls benannt (`Wiki_Bi_Download.txt`) und automatisch in unserem Projektordner gespeichert.\n",
    "\n",
    "Diese Textdatei lesen wir anschließend, wie wir es oben mit der .txt-Datei schon kennengelernt haben, direkt wieder in R ein und können nun, wie oben bereits beschrieben, die nötigen Anpassungen und Bereinigungen vornehmen, um eine Word Cloud zu erstellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6476af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ausgabe/Exportierung des (Tabllen-)Objektes mit Titel und Beschreibung in einer Textdatei (.txt)\n",
    "\n",
    "write.table(Wiki_Bi_Text, \"Wiki_Bi_Download.txt\", sep=\"\\n\", row.names=FALSE, na=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac19ea",
   "metadata": {},
   "source": [
    "## Erstellen der Word Cloud\n",
    "\n",
    "Analog zum Vorgehen bei einer Textdatei erfolgt jetzt das Aufbereiten der Texte als auch das Erstellen der Word Cloud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce1b69",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Script für die Word Cloud: Text einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des Textes Zeile für Zeile\n",
    "Wiki_Bielefeld_down <- stri_read_lines(\"Wiki_Bi_Download.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438616c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Script für die Word Cloud: Textkorpus erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten als Corpus laden \n",
    "docs_down <- Corpus(VectorSource(Wiki_Bielefeld_down))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1752a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Stop Words - \"Stopp-Wörter\" und weitere Aufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5cf965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Großbuchstaben werden zu Kleinbuchstaben \n",
    "docs_down <- tm_map(docs_down, content_transformer(tolower))\n",
    "\n",
    "\n",
    "# Stoppwörter entfernen z.B. der, die, das, und usw. Deutsch und Englisch\n",
    "docs_down <- tm_map(docs_down, removeWords, stopwords(\"english\"))\n",
    "docs_down <- tm_map(docs_down, removeWords, stopwords(\"german\"))\n",
    "\n",
    "\n",
    "# Zahlen entfernen\n",
    "docs_down <- tm_map(docs_down, removeNumbers)\n",
    "\n",
    "\n",
    "# Überschüssige Leerzeichen entfernen\n",
    "docs_down <- tm_map(docs_down, stripWhitespace)\n",
    "\n",
    "\n",
    "# Zeichensetzung entfernen\n",
    "docs_down <- tm_map(docs_down, removePunctuation)\n",
    "\n",
    "\n",
    "# Text aufbereiten entfernen von Sonderzeichen\n",
    "toSpace <- content_transformer(function (x , pattern ) gsub(pattern, \" \", x))\n",
    "docs_down <- tm_map(docs_down, toSpace, \"/\")\n",
    "docs_down <- tm_map(docs_down, toSpace, \"@\")\n",
    "docs_down <- tm_map(docs_down, toSpace, \"\\\\|\")\n",
    "docs_down <- tm_map(docs_down, toSpace, \"-\")\n",
    "\n",
    "\n",
    "# Definieren von eigenen Stoppwörtern\n",
    "docs_down <- tm_map(docs_down, removeWords, c(\n",
    "  \"wurde\", \"sowie\", \"wurden\", \"seit\", \"heute\", \"heut\", \"teil\", \"befindet\", \"weiter\", \"erst\", \"etwa\", \"rund\", \n",
    "  \"gibt\", \"liegt\", \"zwei\", \"statt\", \"weitere\", \"finden\", \"erste\", \"abgerufen\", \"isbn\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c428074",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Script für die Word Cloud: Matrix anlegen und sortierten Datensatz erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier wird eine Matrix angelegt die die Häufigkeit der Begriffe aus den Texten zählbar macht\n",
    "dtm_down <- TermDocumentMatrix(docs_down)\n",
    "m_down <- as.matrix(dtm_down)\n",
    "v_down <- sort(rowSums(m_down),decreasing=TRUE)\n",
    "d_down <- data.frame(word = names(v_down),freq=v_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d95f7aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Script für die Word Cloud:  Word Cloud erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Festlegen einer \"Vorlage\" für die Word Cloud, damit diese reproduziert werden kann und nicht\n",
    "# bei jeder Erstellung zufällig erstellt wird\n",
    "set.seed(1234)\n",
    "\n",
    "\n",
    "# Erstellen der Word Cloud - die Wörter mit der höchsten Frequenz (freq) werden am gröten dargestellt\n",
    "# Die minimale Frequenz damit ein Wort dargestellt wird ist 1\n",
    "# Die Word Cloud besteht aus max. 100 W?rtern (max.Words)\n",
    "# Die Anordnung ist nicht zufällig\n",
    "# rot.per legt fest welcher Anteil an W?rtern nicht waagerecht dargestellt wird\n",
    "w <- Word Cloud(words = d_down$word, freq = d_down$freq,scale=c(8,1), min.freq = 1,\n",
    "          max.words=100, random.order=FALSE, rot.per=0.35, \n",
    "          colors=brewer.pal(8, \"Dark2\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe22d0b7",
   "metadata": {},
   "source": [
    "## Anmerkung zum Unterschied Textdatei und Webdokument\n",
    "\n",
    "Wie du siehst, sind die Word Clouds, die auf der Basis von Textdateien und Webites erstellt wurden, nicht komplett identisch. Gerade die abgerufene Website beinhaltet noch andere Textelemente wie zum Beispiel die Einzelnachweise des Artikels oder auch die Liste deutscher Großstädte. Wir haben also beim Abrufen des Artikels von der Website nicht exakt die gleiche Grundlage, wie bei der Textdatei des Artikels.\n",
    "\n",
    "Dies muss unbedingt bei der Auswertung der beiden Word Clouds berücksichtigt werden. Auch die Aufbereitung wird hierdurch beeinflusst. Beispielsweise ist bei den Stop Words für die Website ein Hinzufügen der Abkürzung \"isbn\" notwendig – ein Wort, das beispielsweise in der Textdatei überhaupt nicht vorkommt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5516569",
   "metadata": {},
   "source": [
    "# Abschluss\n",
    "Wir haben gesehen, dass die Erstellung von Word Clouds auf Grundlage der unterschiedlichsten Textformen als möglich ist. Je nach Textgrundlage und Format ist eine dementsprechende sorgfältige und unterschiedliche Aufbereitung notwendig.\n",
    "\n",
    "Beachtest du dies und kommunizierst offen und transparent, wie deine Word Cloud entstanden ist und auf welcher Datengrundlage sie beruht, steht einer Verwendung bei der nächsten Visualisierung von Daten nichts mehr im Weg!"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "244.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
